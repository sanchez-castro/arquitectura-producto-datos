{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119e2660-dde8-4d97-8d52-effa3610c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b061ce32-3af3-4df2-9445-9713ce9e1fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0e39a2-82e3-4fe9-8a4d-5509940aeb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv...\n",
      "- [1 files][276.7 MiB/276.7 MiB]                                                \n",
      "Operation completed over 1 objects/276.7 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp 'gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv' ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee8a26a-db06-4fc9-87c3-4aae0c5446c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join('.', 'SO_ml_tags_avocado_188k_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b3086d-de68-467d-a696-3019a384e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SO_ml_tags_avocado_188k_v2.csv', names=['tags', 'original_text,', 'text'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b5848f-38ae-406f-8bab-e78b680b8d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>original_text,</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matplotlib,pandas</td>\n",
       "      <td>python,matplotlib,pandas</td>\n",
       "      <td>setting xticks and yticks for scatter plot mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scikitlearn,keras</td>\n",
       "      <td>python,numpy,scikit-learn,keras,grid-search</td>\n",
       "      <td>gridseachcv - valueerror: found input variable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matplotlib,scikitlearn</td>\n",
       "      <td>python,numpy,matplotlib,scikit-learn,nmf</td>\n",
       "      <td>non negative matrix factorisation in python on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pandas,tensorflow</td>\n",
       "      <td>python,pandas,tensorflow,time-series</td>\n",
       "      <td>avocado equivalent to avocado.dataframe.resamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>matplotlib,pandas</td>\n",
       "      <td>python,matplotlib,plot,pandas</td>\n",
       "      <td>how to plot on avocado python i have a data fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tags                               original_text,  \\\n",
       "0       matplotlib,pandas                     python,matplotlib,pandas   \n",
       "1       scikitlearn,keras  python,numpy,scikit-learn,keras,grid-search   \n",
       "2  matplotlib,scikitlearn     python,numpy,matplotlib,scikit-learn,nmf   \n",
       "3       pandas,tensorflow         python,pandas,tensorflow,time-series   \n",
       "4       matplotlib,pandas                python,matplotlib,plot,pandas   \n",
       "\n",
       "                                                text  \n",
       "0  setting xticks and yticks for scatter plot mat...  \n",
       "1  gridseachcv - valueerror: found input variable...  \n",
       "2  non negative matrix factorisation in python on...  \n",
       "3  avocado equivalent to avocado.dataframe.resamp...  \n",
       "4  how to plot on avocado python i have a data fr...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09234265-2c81-4493-a139-13899c4ba9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a290162-bcde-496b-a7fd-277a40cc1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['original_text,'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448374ec-3610-44ad-8d87-533747b74953",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f8b354-c660-4d12-a365-114a8acac6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70357</th>\n",
       "      <td>pandas</td>\n",
       "      <td>sqlalchemy is too slow, did i do anything wron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152810</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>getting \"no module named queue\" when installin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180803</th>\n",
       "      <td>tensorflow,keras</td>\n",
       "      <td>why does sigmoid &amp; crossentropy of avocado/avo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186450</th>\n",
       "      <td>pandas,matplotlib</td>\n",
       "      <td>plot avocado columns with secondary y -axis an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52130</th>\n",
       "      <td>pandas</td>\n",
       "      <td>“unknown string format”-error when parsing url...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tags                                               text\n",
       "70357              pandas  sqlalchemy is too slow, did i do anything wron...\n",
       "152810         tensorflow  getting \"no module named queue\" when installin...\n",
       "180803   tensorflow,keras  why does sigmoid & crossentropy of avocado/avo...\n",
       "186450  pandas,matplotlib  plot avocado columns with secondary y -axis an...\n",
       "52130              pandas  “unknown string format”-error when parsing url..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shuffle(data, random_state=20)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "519ada55-04d2-4549-99fe-7dbc33ec2da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlalchemy is too slow, did i do anything wrong? when i do this command using mamp with mysql:  select * from cont_bar   it only takes (264,278 total, query took 0.0007 seconds.) however, when i try to load this table into a avocado data_frame, it becomes pretty slow. i tried two approaches.  first approach  import avocado as avocado from sqlalchemy import create_engine  engine = create_engine(\"mysql://{}:{}@{}:{}/{}\".format(db_user, db_password, db_host, db_port, future_daily_bar_db))  conn = engine.connect() resoverall = conn.execute(\"select * from cont_bar\") full_avocado = avocado.dataframe(resoverall.fetchall()) full_avocado.columns = resoverall.keys()   this one takes 20s.   second approach  engine = create_engine(\"mysql://{}:{}@{}:{}/{}\".format(db_user, db_password, db_host, db_port, future_daily_bar_db)) conn = engine.connect() full_avocado_2 = avocado.read_sql(\"select * from cont_bar\", conn)   this one takes 37s. i think this is really slow. is it the best sqlalchemy/any other mysql based python package can do?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "358a05ea-44b4-4c8a-88a9-9ff63041e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_split = [tags.split(',') for tags in data['tags'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e22f21f-7600-46d5-a024-393e9beda84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tensorflow', 'keras']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_split[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1914bbaa-a5cd-4b88-ad61-2250b071f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_encoder = MultiLabelBinarizer()\n",
    "tags_encoded = tag_encoder.fit_transform(tags_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5743661e-1249-46ae-8b22-e29cf2646bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags =len(tags_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27e92d47-281a-40a9-9677-c21a5dd37ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5742531-a5e6-4823-aeba-be6cbcadaf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keras' 'matplotlib' 'pandas' 'scikitlearn' 'tensorflow']\n"
     ]
    }
   ],
   "source": [
    "print(tag_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8a53f72-cb03-4aec-868d-bcae6cecb7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "671a3333-c315-4f67-800d-39ef0ee53534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_encoded[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfec959d-938a-4e0b-9d79-e41ae6cde842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 150559\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data)*.8)\n",
    "print(\"train size: %d\" % train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02505ff1-1dee-4748-bb40-2283fe2e79e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 37640\n"
     ]
    }
   ],
   "source": [
    "print(\"test size: %d\" % (len(data) -train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03984ac1-44d2-490c-885f-1574dbba51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags = tags_encoded[:train_size]\n",
    "test_tags = tags_encoded[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b842af1-835b-4914-b890-569081a163b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581de0a7-64a9-4169-9a8d-926ce291d746",
   "metadata": {},
   "source": [
    "# Feature Engineering for our X's (predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70762d7e-75d9-4057-8d5d-7d18c51f028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "from tensorflow.keras.preprocessing import text\n",
    "\n",
    "class TextPreprocessor(object):\n",
    "    def __init__(self, vocab_size):\n",
    "        self._vocab_size = vocab_size\n",
    "        self._tokenizer = None\n",
    "        \n",
    "    def create_tokenizer(self, text_list):\n",
    "        tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
    "        tokenizer.fit_on_texts(text_list)\n",
    "        self._tokenizer = tokenizer\n",
    "    \n",
    "    def transform_text(self, text_list):\n",
    "        text_matrix=self._tokenizer.texts_to_matrix(text_list)\n",
    "        return text_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a64b6ca7-c537-4692-a893-8b38a486449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import TextPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ef21359-d7e7-4e47-8f4a-7a76aca8dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qs = data['text'].values[:train_size]\n",
    "test_qs =data['text'].values[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dec14a2-7697-4877-bcb7-1268ffcbdbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b63d25af-3686-4cbc-a3ee-931b6aad54d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocess.TextPreprocessor"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE=400\n",
    "processor = TextPreprocessor(VOCAB_SIZE)\n",
    "type(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3ce8572-9eae-47be-ba66-77babb4f5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.create_tokenizer(train_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e4559a7-8a0d-4e18-9e54-f1849c6cadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_train = processor.transform_text(train_qs)\n",
    "body_test = processor.transform_text(test_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b592854-f474-4cbe-b723-41acaba07121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(body_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07d8aaed-704f-4c59-8557-1443dae0e294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(body_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbe35615-f79b-4655-b5ee-f6efd1f0f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./processor_state.pkl', 'wb') as f:\n",
    "    pickle.dump(processor,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4af2c-1545-46cf-8d1b-78d942260bd0",
   "metadata": {},
   "source": [
    "# Build and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83fe4093-935a-480d-a945-a70394025cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, num_tags):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(50, input_shape=(VOCAB_SIZE,), activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(num_tags, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "                  \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c717b05-5240-4409-ae20-65d50f4c0388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 14:44:52.540466: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-03-22 14:44:52.577231: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-22 14:44:52.577300: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vm-1a1132b4-6adb-45c9-b1ce-76bd1b8b9bc5): /proc/driver/nvidia/version does not exist\n",
      "2022-03-22 14:44:52.616817: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model =create_model(VOCAB_SIZE, num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2f64cd9-b17f-4d6d-a707-cbc06f7245cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                20050     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,455\n",
      "Trainable params: 21,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b522c80-c80e-488f-9f39-1ec7bab36c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 14:44:54.096073: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 216804800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1058/1059 [============================>.] - ETA: 0s - loss: 0.1430 - accuracy: 0.8599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 14:45:09.314140: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24089600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 15s 11ms/step - loss: 0.1429 - accuracy: 0.8600 - val_loss: 0.1129 - val_accuracy: 0.8917\n",
      "Epoch 2/5\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.1043 - accuracy: 0.8952 - val_loss: 0.1061 - val_accuracy: 0.8934\n",
      "Epoch 3/5\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.0981 - accuracy: 0.8982 - val_loss: 0.1049 - val_accuracy: 0.8944\n",
      "Epoch 4/5\n",
      "1059/1059 [==============================] - 10s 10ms/step - loss: 0.0941 - accuracy: 0.9015 - val_loss: 0.1026 - val_accuracy: 0.8968\n",
      "Epoch 5/5\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0908 - accuracy: 0.9038 - val_loss: 0.1040 - val_accuracy: 0.8971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac27458e10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(body_train, train_tags, epochs=5, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cb0ce36-50bb-419f-bb01-7448e2e23e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35/295 [==>...........................] - ETA: 0s - loss: 0.0951 - accuracy: 0.9013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 14:46:19.733312: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 60224000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 1s 4ms/step - loss: 0.1005 - accuracy: 0.8993\n",
      "Eval loss/accuracy:[0.10052843391895294, 0.899282693862915]\n"
     ]
    }
   ],
   "source": [
    "print('Eval loss/accuracy:{}'.format(model.evaluate(body_test, test_tags, batch_size=128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "850089e9-a563-4569-97f1-fd3e82aa5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ef728eb-a511-4b58-a5bc-ff19ea5cbe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_prediction.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_prediction.py\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class CustomModelPrediction(object):\n",
    "    def __init__(self, model, processor):\n",
    "        self._model= model\n",
    "        self._processor = processor\n",
    "    \n",
    "    def predict(self, instances, **kwargs):\n",
    "        preprocessed_data = self._processor.transform_text(instances)\n",
    "        predictions = self._model.predict(preprocessed_data)\n",
    "        return predictions.tolist()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_path(cls, model_dir):\n",
    "        import os\n",
    "        import tensorflow.keras as keras\n",
    "        model = keras.models.load_model(os.path.join(model_dir,'keras_saved_model.h5'))\n",
    "        with open(os.path.join(model_dir, 'processor_state.pkl'), 'rb') as f:\n",
    "                  processor = pickle.load(f)\n",
    "        return cls(model, processor)\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b8aefed-1904-428b-9408-dbeeddfab61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_prediction import CustomModelPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aecae44e-dab5-4a5d-9b6b-64fa0f36cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CustomModelPrediction.from_path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "388d6497-5283-4ed2-b615-5d22b4a34a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_request = [\n",
    "  \"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?, 1] def text_preprocess(x): strings = tf.keras.backend.eval(x) vectors = [] for string in strings: vector = string_to_one_hot(string.decode('utf-8')) vectors.append(vector) vectorTensor = tf.constant(np.array(vectors),dtype=tf.float32) return vectorTensor input_text = Input(shape=(1,), dtype=tf.string) embedding = Lambda(text_preprocess)(input_text) dense = Dense(256, activation='relu')(embedding) outputs = Dense(2, activation='softmax')(dense) model = Model(inputs=[input_text], outputs=outputs) model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) model.summary() model.save('test.h5') If I pass a string array into the input layer statically, I can compile the model, but I get the same error if I want to convert the model to tflite. #I replaced this line: input_text = Input(shape=(1,), dtype=tf.string) #by this lines: test = tf.constant(['Hello', 'World']) input_text = Input(shape=(1,), dtype=tf.string, tensor=test) #but calling this ... converter = TFLiteConverter.from_keras_model_file('string_test.h5') tfmodel = converter.convert() #... still leads to this error: InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype string and shape [2] [[{{node input_3}}]] \",\n",
    "  \"Change the bar item name in Pandas I have a test excel file like: df = pd.DataFrame({'name':list('abcdefg'), 'age':[10,20,5,23,58,4,6]}) print (df) name  age 0    a   10 1    b   20 2    c    5 3    d   23 4    e   58 5    f    4 6    g    6 I use Pandas and matplotlib to read and plot it: import pandas as pd import numpy as np import matplotlib.pyplot as plt import os excel_file = 'test.xlsx' df = pd.read_excel(excel_file, sheet_name=0) df.plot(kind='bar') plt.show() the result shows: enter image description here it use index number as item name, how can I change it to the name, which stored in column name?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a76f5c4-8028-4323-83c3-1d186b709414",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=classifier.predict(test_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc59c13a-1c85-454e-80b6-de5310f84f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.942192792892456,\n",
       " 0.00045877695083618164,\n",
       " 0.0001958012580871582,\n",
       " 0.0010537803173065186,\n",
       " 0.7719775438308716]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ac4c63c-8a08-4377-ab74-d4643674b64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels for text-0:\n",
      "keras\n",
      "tensorflow\n",
      "\n",
      "\n",
      "Predicted labels for text-1:\n",
      "matplotlib\n",
      "pandas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "  print('Predicted labels for text-{}:'.format(i))\n",
    "  for idx, val in enumerate(results[i]):\n",
    "    if val > 0.7:\n",
    "      print(tag_encoder.classes_[idx])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc46ba0-ef42-420d-b3fc-b495cf51ed38",
   "metadata": {},
   "source": [
    "# Package our Model and deploy it INTO AI PLATFORM!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eefcfc82-766e-4ce2-b97c-4005b08584ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project itam-dpa-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f32d5aa5-44cd-460d-9a1e-10c7090a58b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [ai_platform/region].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set ai_platform/region global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4e3749d-8ffd-4d81-a81a-540fbfa5ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://keras_saved_model.h5 [Content-Type=application/x-hdf5]...\n",
      "/ [1 files][282.8 KiB/282.8 KiB]                                                \n",
      "Operation completed over 1 objects/282.8 KiB.                                    \n",
      "Copying file://processor_state.pkl [Content-Type=application/octet-stream]...\n",
      "- [1 files][ 32.3 MiB/ 32.3 MiB]                                                \n",
      "Operation completed over 1 objects/32.3 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp keras_saved_model.h5 gs://itam-dpa-2022-text-classifier/v2/\n",
    "!gsutil cp processor_state.pkl gs://itam-dpa-2022-text-classifier/v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9aaa8ec-c207-4914-b22f-24a55f09e914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "    name=\"so_predict\",\n",
    "    version=\"0.2\",\n",
    "    include_package_data=True,\n",
    "    scripts=[\"preprocess.py\", \"model_prediction.py\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90756bf0-d358-43dd-8b5e-0afd6e42e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "creating so_predict.egg-info\n",
      "writing so_predict.egg-info/PKG-INFO\n",
      "writing dependency_links to so_predict.egg-info/dependency_links.txt\n",
      "writing top-level names to so_predict.egg-info/top_level.txt\n",
      "writing manifest file 'so_predict.egg-info/SOURCES.txt'\n",
      "reading manifest file 'so_predict.egg-info/SOURCES.txt'\n",
      "writing manifest file 'so_predict.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating so_predict-0.2\n",
      "creating so_predict-0.2/so_predict.egg-info\n",
      "copying files to so_predict-0.2...\n",
      "copying model_prediction.py -> so_predict-0.2\n",
      "copying preprocess.py -> so_predict-0.2\n",
      "copying setup.py -> so_predict-0.2\n",
      "copying so_predict.egg-info/PKG-INFO -> so_predict-0.2/so_predict.egg-info\n",
      "copying so_predict.egg-info/SOURCES.txt -> so_predict-0.2/so_predict.egg-info\n",
      "copying so_predict.egg-info/dependency_links.txt -> so_predict-0.2/so_predict.egg-info\n",
      "copying so_predict.egg-info/top_level.txt -> so_predict-0.2/so_predict.egg-info\n",
      "Writing so_predict-0.2/setup.cfg\n",
      "creating dist\n",
      "Creating tar archive\n",
      "removing 'so_predict-0.2' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!python setup.py sdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa166e04-72c4-4fc0-bd8f-31475aaeb7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./dist/so_predict-0.2.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  1.1 KiB/  1.1 KiB]                                                \n",
      "Operation completed over 1 objects/1.1 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./dist/so_predict-0.2.tar.gz gs://itam-dpa-2022-text-classifier/v2/packages/so_predict-0.2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05ffbf48-425e-4f4c-98bb-39b5aac817de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m To specify a region where the model will deployed on the global endpoint, please use `--regions` and do not specify `--region`. Using [us-central1] by default on https://ml.googleapis.com. Please note that your model will be inaccessible from https://us-central1-ml.googelapis.com\n",
      "\n",
      "Learn more about regional endpoints and see a list of available regions: https://cloud.google.com/ai-platform/prediction/docs/regional-endpoints\n",
      "Using endpoint [https://ml.googleapis.com/]\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.models.create) Resource in projects [itam-dpa-2022] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create itam_dpa_2022_text_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7bc24342-c0f4-4993-90cc-be9a39f6b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "093d7cb0-2fd2-47f7-936d-cf937f3455d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow @ file:///opt/conda/conda-bld/dlenv-tf-2-8-gpu_1643754343905/work/tensorflow-2.8.0-cp37-cp37m-linux_x86_64.whl\n",
      "tensorflow-cloud==0.1.16\n",
      "tensorflow-datasets==4.4.0\n",
      "tensorflow-estimator==2.8.0\n",
      "tensorflow-hub==0.12.0\n",
      "tensorflow-io==0.23.1\n",
      "tensorflow-io-gcs-filesystem==0.23.1\n",
      "tensorflow-metadata==1.6.0\n",
      "tensorflow-probability==0.14.1\n",
      "tensorflow-serving-api==2.7.0\n",
      "tensorflow-transform==1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f6cde-6ad2-4d78-b222-b85cb15c2ef1",
   "metadata": {},
   "source": [
    "!gcloud beta ai-platform versions create v2\n",
    "--model itam_dpa_2022_text_classifier \n",
    "--python-version 3.7 \n",
    "--runtime-version 2.7  \n",
    "--origin gs://itam-dpa-2022-text-classifier/v1/ \n",
    "--package-uris gs://itam-dpa-2022-text-classifier/v1/packages/so_predict-0.1.tar.gz \n",
    "--prediction-class model_prediction.CustomModelPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55439658-b040-429b-a5a2-ce6d4ae8d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai-platform versions create v2 --model itam_dpa_2022_text_classifier --python-version 3.7 --runtime-version 2.7  --origin gs://itam-dpa-2022-text-classifier/v2/ --package-uris gs://itam-dpa-2022-text-classifier/v2/packages/so_predict-0.2.tar.gz --prediction-class model_prediction.CustomModelPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1b4002d-6bc9-4488-930e-a7fc668776fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictions.txt\n",
    "\"I have a pandas data set, called 'df'. How can I do something like below;df.query(\\\"select * from df\\\") Thank you.For those who know R, there is a library called sqldf where you can execute SQL code in R, my question is basically, is there some library like sqldf in python\"\n",
    "\"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error\"\n",
    "\"I have a test excel file like:df = pd.DataFrame({'name':list('abcdefg'), 'age':[10,20,5,23,58,4,6]})print (df)name  age0    a   101    b   202    c    53    d   234    e   585    f    46    g    6I use Pandas and matplotlib to read and plot it:import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport osexcel_file = 'test.xlsx'df = pd.read_excel(excel_file, sheet_name=0)df.plot(kind='bar')plt.show()the result shows: enter image description hereit use index number as item name, how can I change it to the name, which stored in column name?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "200bc65e-5c4b-45ac-8f49-fe5532e4c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = !gcloud ai-platform predict --model=itam_dpa_2022_text_classifier --version=v1 --text-instances=predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0110a142-87fd-4a4d-9f2b-f57b1ce7234c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Using endpoint [https://ml.googleapis.com/]',\n",
       " '[[0.004557758569717407, 0.22688749432563782, 0.7872121334075928, 0.08959212899208069, 0.0027919113636016846], [0.35895562171936035, 0.001184225082397461, 0.014009594917297363, 0.03241389989852905, 0.7719103097915649], [7.194867794169113e-05, 0.7333732843399048, 0.7804746627807617, 0.0009480714797973633, 2.0992163626942784e-05]]']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7862a8f-4074-4c34-871f-9d0e2bc44928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004557758569717407, 0.22688749432563782, 0.7872121334075928, 0.08959212899208069, 0.0027919113636016846]\n",
      "pandas\n",
      "\n",
      "\n",
      "[0.35895562171936035, 0.001184225082397461, 0.014009594917297363, 0.03241389989852905, 0.7719103097915649]\n",
      "tensorflow\n",
      "\n",
      "\n",
      "[7.194867794169113e-05, 0.7333732843399048, 0.7804746627807617, 0.0009480714797973633, 2.0992163626942784e-05]\n",
      "matplotlib\n",
      "pandas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sigmoid_arr in eval(predictions[1]):\n",
    "  print(sigmoid_arr)\n",
    "  for idx,probability in enumerate(sigmoid_arr):\n",
    "    if probability > 0.7:\n",
    "      print(tag_encoder.classes_[idx])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b92eefe6-227e-4cab-b3b1-2fc379d148b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = !gcloud ai-platform predict --model=itam_dpa_2022_text_classifier --version=v2 --text-instances=predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fec58f02-d070-481f-8088-229b5fdef696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Using endpoint [https://ml.googleapis.com/]',\n",
       " '[[0.0113944411277771, 0.1355363130569458, 0.8665759563446045, 0.087117999792099, 0.00860169529914856], [0.43351656198501587, 0.002308487892150879, 0.006677567958831787, 0.013029724359512329, 0.8900078535079956], [2.8874205781903584e-06, 0.8157265186309814, 0.8848062753677368, 0.0002879500389099121, 1.5626831100234995e-06]]']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96b4eadf-991d-4de2-ac83-b12648f9e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0113944411277771, 0.1355363130569458, 0.8665759563446045, 0.087117999792099, 0.00860169529914856]\n",
      "pandas\n",
      "\n",
      "\n",
      "[0.43351656198501587, 0.002308487892150879, 0.006677567958831787, 0.013029724359512329, 0.8900078535079956]\n",
      "tensorflow\n",
      "\n",
      "\n",
      "[2.8874205781903584e-06, 0.8157265186309814, 0.8848062753677368, 0.0002879500389099121, 1.5626831100234995e-06]\n",
      "matplotlib\n",
      "pandas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sigmoid_arr in eval(predictions2[1]):\n",
    "  print(sigmoid_arr)\n",
    "  for idx,probability in enumerate(sigmoid_arr):\n",
    "    if probability > 0.7:\n",
    "      print(tag_encoder.classes_[idx])\n",
    "  print('\\n')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu:latest"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
